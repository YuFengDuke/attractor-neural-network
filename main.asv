clear;

Cs = linspace(0.1,0.5,10);
X = [];
for c = Cs
% network size
N = 2000;

% connection prob
%c = 0.1;

% coding level, f = 0.5 corresponds to Hopfield Model.
% when f is smaller than 0.5, the activation threshold should also changes,
% otherwise the capacity will be extremely small. 
f = 0.5;

% this number should be optimzed when f not equal 0.5
activation_threshold = 0;

% the number of sample to estimate the average overlap
sample_size = 20;

%memory load = stored pattern / network size
memory_load = 0.01:0.01:0.2;

%number of patterns
pattern_numbers = ceil(c * N * memory_load);


average_overlaps = zeros(size(pattern_numbers));
std_overlaps = zeros(size(pattern_numbers));

for i = 1:size(pattern_numbers,2)
    disp(['memory load alpha = ', num2str(memory_load(i))]);
    mu = pattern_numbers(i);
    sample_size = min(mu, sample_size);
    constant = set_parameter(N, c, mu, f, activation_threshold, sample_size);
    
    % patterns to be learned
    patterns = generate_pattern(N, mu, f);
    [average_overlap, std_overlap, graph] = attractor_neural_network(patterns, constant);
    average_overlaps(i) = average_overlap;
    std_overlaps(i) = std_overlap;
end
    index = find(average_overlaps<0.95);
    x = memory_load(index(1)-1);
    X = [X,x];
    disp(X);
end
% the capacity for fully connected Hopfield network should be ~0.13 (f = 0.5)
% In the sparse coding case, the capacity should be larger than 0.3 (e.g.,f = 0.05)

index = find(average_overlaps<0.95);
average_overlaps(index) = 0;
std_overlaps(index) = 0;

figure;
plot(memory_load, average_overlaps,'s', 'LineWidth', 4);
xlabel('$\alpha$','Interpreter','latex');
ylabel('$m$','Interpreter','latex');
set(gca, 'FontSize',36);
set(gcf, 'position', [0 0 900 800]);